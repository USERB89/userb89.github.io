#!/usr/bin/env python3
# build_arabic_corpus_test.py
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–±–æ—Ä—â–∏–∫ –∞—Ä–∞–±—Å–∫–∏—Ö —Å–ª–æ–≤ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
- –†–∞–±–æ—Ç–∞–µ—Ç –≤ TEST_MODE (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True) ‚Äî —Å–∫–∞—á–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ TEST_BYTES –±–∞–π—Ç –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞,
  –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä–∞–±—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—Å–ª–æ–≤–∞/—Ñ–æ—Ä–º—ã) –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ CSV.
- –ü—Ä–∏ TEST_MODE=False –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è / —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏.
"""

import os
import re
import csv
import sys
import requests
import zipfile
from io import BytesIO

# ========== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ==========
TEST_MODE = False          # True = —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (–º–∞–ª–µ–Ω—å–∫–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏); False = –ø–æ–ª–Ω—ã–π —Ä–µ–∂–∏–º
TEST_BYTES = 50 * 1024   # —Å–∫–æ–ª—å–∫–æ –±–∞–π—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ (50 KB) ‚Äî –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å/—É–≤–µ–ª–∏—á–∏—Ç—å
DATA_DIR = os.path.join(os.path.dirname(__file__), "datasets")
OUT_CSV = os.path.join(os.path.dirname(__file__), "arabic_words_test.csv")
os.makedirs(DATA_DIR, exist_ok=True)

# –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –î–ª—è –∫–∞–∂–¥–æ–≥–æ: name, url, type_hint (txt|zip|raw)
SOURCES = [
    ("quranic", "https://corpus.quran.com/download/wordbyword.txt", "txt"),
    ("arabic_wordlist_cjki", "https://raw.githubusercontent.com/linuxscout/arabic-wordlist/master/arabic.txt", "txt"),
    ("qabas", "https://github.com/arabic-tools/qabas/archive/refs/heads/main.zip", "zip"),
    ("arablex", "https://www.cjk.org/data/arabic/nlp/arablex-arabic-full-form-lexicon/arablex.zip", "zip"),  # –ø—Ä–∏–º–µ—Ä
    ("camel", "https://github.com/CAMeL-Lab/Camel_Arabic_Frequency_Lists/archive/refs/heads/master.zip", "zip"),
    ("kalimat", "https://sourceforge.net/projects/kalimat/files/kalimat/kalimat.zip/download", "zip"),
]

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞—Ä–∞–±—Å–∫–∏—Ö –±—É–∫–≤ + –æ–≥–ª–∞—Å–æ–≤–æ–∫ (–≤–∫–ª—é—á–∞—è —Ç—Ä–µ–≤–∏–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã)
ARABIC_RE = re.compile(r"[\u0600-\u06FF\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06ED]+")

# –î–∏–∞–∫—Ä–∏—Ç–∏–∫–∏/–æ–≥–ª–∞—Å–æ–≤–∫–∏ (–¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ word_without_tashkeel)
DIACRITICS_RE = re.compile(
    "[" +
    "\u0610-\u061A" +  # Quranic annotation signs
    "\u064B-\u0652" +  # tashkeel
    "\u06D6-\u06ED" +  # more signs
    "\u0670" +
    "]"
)

HEADERS = {"User-Agent": "Mozilla/5.0 (compatible; arabic-corpus-test/1.0)"}

# ========== –§—É–Ω–∫—Ü–∏–∏ ==========
def fetch_head_bytes(url, max_bytes=TEST_BYTES):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –ø–µ—Ä–≤—ã–µ max_bytes –±–∞–π—Ç —Ä–µ—Å—É—Ä—Å–∞ (stream). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes."""
    try:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ—Å —Å Range –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (—Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ –≤–µ–∑–¥–µ, –Ω–æ —á–∞—Å—Ç–æ)
        headers = dict(HEADERS)
        headers["Range"] = f"bytes=0-{max_bytes-1}"
        r = requests.get(url, headers=headers, timeout=30, stream=True)
        if r.status_code in (200, 206):
            chunk = r.content
            return chunk
        else:
            # fallback: –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –Ω–æ —á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å
            r = requests.get(url, headers=HEADERS, stream=True, timeout=30)
            content = b""
            for part in r.iter_content(chunk_size=8192):
                content += part
                if len(content) >= max_bytes:
                    break
            return content
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")
        return b""

def extract_arabic_from_bytes(bdata):
    """–ò—â–µ—Ç –∞—Ä–∞–±—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ bytes, –ø—ã—Ç–∞—è—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤ utf-8/latin1."""
    if not bdata:
        return []
    for encoding in ("utf-8", "windows-1256", "latin1"):
        try:
            text = bdata.decode(encoding, errors="ignore")
            words = ARABIC_RE.findall(text)
            if words:
                return words
        except Exception:
            continue
    return []

def process_txt_source(name, url, out_set):
    print(f"\nüîΩ –¢–µ–∫—Å—Ç–æ–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫: {name} -> {url}")
    data = fetch_head_bytes(url)
    words = extract_arabic_from_bytes(data)
    n = 0
    for w in words:
        out_set.add((w, DIACRITICS_RE.sub("", w), name))
        n += 1
        if TEST_MODE and n >= 20:  # –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ —Å–ª–æ–≤–∞–º/–∏—Å—Ç–æ—á–Ω–∏–∫—É
            break
    print(f"   –¥–æ–±–∞–≤–ª–µ–Ω–æ {min(len(words), 20) if TEST_MODE else len(words)} —Å–ª–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ)")

def process_zip_source(name, url, out_set):
    print(f"\nüîΩ ZIP –∏—Å—Ç–æ—á–Ω–∏–∫: {name} -> {url}")
    # –°–∫–∞—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ bytes; –∑–∞—Ç–µ–º –ø—ã—Ç–∞–µ–º—Å—è –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–∫ zip (–≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –º–æ–∂–µ—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å)
    data = fetch_head_bytes(url)
    # –ü–æ–ø—Ä–æ–±—É–µ–º –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–∫ zip –ø–æ–ª–Ω–æ—Å—Ç—å—é ‚Äî –µ—Å–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–π –∫—É—Å–æ–∫ –Ω–µ–ø–æ–ª–Ω—ã–π, zipfile.BadZipFile –º–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å
    try:
        bio = BytesIO(data)
        with zipfile.ZipFile(bio) as z:
            # –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–∞–º –≤ –∞—Ä—Ö–∏–≤–µ
            members = z.namelist()
            count = 0
            for member in members:
                if member.endswith((".txt", ".csv", ".tsv")):
                    with z.open(member) as f:
                        try:
                            text = f.read().decode("utf-8", errors="ignore")
                        except:
                            continue
                        words = ARABIC_RE.findall(text)
                        for w in words:
                            out_set.add((w, DIACRITICS_RE.sub("", w), name))
                            count += 1
                            if TEST_MODE and count >= 20:
                                break
                if TEST_MODE and count >= 20:
                    break
            print(f"   –∏–∑–≤–ª–µ—á–µ–Ω–æ {count} —Å–ª–æ–≤ –∏–∑ –∞—Ä—Ö–∏–≤–∞ (–µ—Å–ª–∏ –∞—Ä—Ö–∏–≤ –¥–æ—Å—Ç—É–ø–µ–Ω)")
            return
    except zipfile.BadZipFile:
        # –ù–µ –ø–æ–ª–Ω—ã–π ZIP ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –∞—Ä–∞–±—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Å—ã—Ä–æ–º –±–∞–π—Ç-–∫—É—Å–∫–µ
        words = extract_arabic_from_bytes(data)
        cnt = 0
        for w in words:
            out_set.add((w, DIACRITICS_RE.sub("", w), name))
            cnt += 1
            if TEST_MODE and cnt >= 20:
                break
        print(f"   ZIP –Ω–µ–ø–æ–ª–Ω—ã–π/–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –Ω–∞–π–¥–µ–Ω–æ {cnt} –∞—Ä–∞–±—Å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ —Å–∫–∞—á–∞–Ω–Ω–æ–º –∫—É—Å–∫–µ")
    except Exception as e:
        print(f"   –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ ZIP: {e}")

# ========== MAIN ==========
def main():
    all_words = set()  # (with_tashkeel, without_tashkeel, source)

    for name, url, kind in SOURCES:
        if kind == "txt":
            process_txt_source(name, url, all_words)
        elif kind == "zip":
            process_zip_source(name, url, all_words)
        else:
            # –æ–±—â–∏–π –ø—É—Ç—å: —Å–∫–∞—á–∞—Ç—å –∫—É—Å–æ–∫ –∏ –∏—Å–∫–∞—Ç—å –∞—Ä–∞–±—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            print(f"\nüîΩ (generic) {name} -> {url}")
            data = fetch_head_bytes(url)
            words = extract_arabic_from_bytes(data)
            cnt = 0
            for w in words:
                all_words.add((w, DIACRITICS_RE.sub("", w), name))
                cnt += 1
                if TEST_MODE and cnt >= 20:
                    break
            print(f"   –Ω–∞–π–¥–µ–Ω–æ {cnt} —Å–ª–æ–≤ (generic)")

       # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ CSV
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ {OUT_CSV} ...")
    with open(OUT_CSV, "w", encoding="utf-8", newline="") as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["word_with_tashkeel", "word_without_tashkeel", "source"])
        # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        for w_with, w_no, src in sorted(all_words, key=lambda x: (x[2], x[0])):
            writer.writerow([w_with, w_no, src])

    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ. –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(all_words)}")
    print(f"–§–∞–π–ª: {OUT_CSV}")
    if TEST_MODE:
        print("\nüîé –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: —Å–∫–∞—á–∞–Ω–æ —Ç–æ–ª—å–∫–æ –Ω–µ–±–æ–ª—å—à–∏–µ –∫—É—Å–∫–∏ (TEST_BYTES).")
        print("–ï—Å–ª–∏ –≤—Å—ë –æ–∫ ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∏ TEST_MODE = False –∏ –∑–∞–ø—É—Å—Ç–∏ —Å–Ω–æ–≤–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è/–æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    else:
        print("\n‚ÑπÔ∏è –ü–æ–ª–Ω—ã–π —Ä–µ–∂–∏–º: —Å–∫—Ä–∏–ø—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Ä–∞–±–æ—Ç–∞–Ω –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –±–æ–ª—å—à–∏—Ö –∞—Ä—Ö–∏–≤–æ–≤ –∏ –∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

if __name__ == "__main__":
    main()
